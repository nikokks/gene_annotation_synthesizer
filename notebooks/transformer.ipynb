{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://www.tensorflow.org/text/tutorials/transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:20.434816Z",
     "iopub.status.busy": "2021-08-25T11:11:20.434262Z",
     "iopub.status.idle": "2021-08-25T11:11:22.672326Z",
     "shell.execute_reply": "2021-08-25T11:11:22.672695Z"
    },
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJxTd6aVnZyh"
   },
   "source": [
    "## Text detokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_folder = '../data/tokenizer_folder/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the tokenizer using vocab.json and mrege.txt files\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    os.path.abspath(os.path.join(tokenizer_folder,'vocab.json')),\n",
    "    os.path.abspath(os.path.join(tokenizer_folder,'merges.txt'))\n",
    ")\n",
    "# Prepare the tokenizer\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)\n",
    "# Test the tokenizer\n",
    "# Show the tokens created\n",
    "tokenizer.encode(\"test\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.023578Z",
     "iopub.status.busy": "2021-08-25T11:11:30.022721Z",
     "iopub.status.idle": "2021-08-25T11:11:30.024582Z",
     "shell.execute_reply": "2021-08-25T11:11:30.025036Z"
    },
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    " \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.436550Z",
     "iopub.status.busy": "2021-08-25T11:11:30.435988Z",
     "iopub.status.idle": "2021-08-25T11:11:30.437551Z",
     "shell.execute_reply": "2021-08-25T11:11:30.437867Z"
    },
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.468352Z",
     "iopub.status.busy": "2021-08-25T11:11:30.467812Z",
     "iopub.status.idle": "2021-08-25T11:11:30.469623Z",
     "shell.execute_reply": "2021-08-25T11:11:30.469937Z"
    },
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikkokks/.local/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "\n",
    "model = pretrained_model_generator.create_model(512)\n",
    "# model = pretrained_model_generator.create_model_function(512,100000,0)\n",
    "model = get_model_with_hidden_layers_as_outputs(model)\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3.   Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next token by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.561487Z",
     "iopub.status.busy": "2021-08-25T11:11:30.560942Z",
     "iopub.status.idle": "2021-08-25T11:11:30.562957Z",
     "shell.execute_reply": "2021-08-25T11:11:30.563279Z"
    },
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.573952Z",
     "iopub.status.busy": "2021-08-25T11:11:30.573399Z",
     "iopub.status.idle": "2021-08-25T11:11:30.623958Z",
     "shell.execute_reply": "2021-08-25T11:11:30.623533Z"
    },
    "id": "Ne2Bqx8k71l0"
   },
   "outputs": [],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 1562)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.630988Z",
     "iopub.status.busy": "2021-08-25T11:11:30.630463Z",
     "iopub.status.idle": "2021-08-25T11:11:30.632377Z",
     "shell.execute_reply": "2021-08-25T11:11:30.632699Z"
    },
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        model.trainable = training\n",
    "        rep = model.predict(x)\n",
    "        return rep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "model = pretrained_model_generator.create_model(seq_len)\n",
    "# model = pretrained_model_generator.create_model_function(512,100000,0)\n",
    "model = get_model_with_hidden_layers_as_outputs(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.638724Z",
     "iopub.status.busy": "2021-08-25T11:11:30.638201Z",
     "iopub.status.idle": "2021-08-25T11:11:30.892503Z",
     "shell.execute_reply": "2021-08-25T11:11:30.892879Z"
    },
    "id": "8QG9nueFQKXx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 512), dtype=int32, numpy=\n",
      "array([[23, 22, 22, ..., 25, 25, 25],\n",
      "       [23, 22, 22, ..., 25, 25, 25]], dtype=int32)>, <tf.Tensor: shape=(2, 8943), dtype=int8, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)>]\n",
      "(2, 512, 1562)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder()\n",
    "\n",
    "sample_encoder_output = sample_encoder(input_encoder.encode_X(['test','test2'],512), training=False)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.900884Z",
     "iopub.status.busy": "2021-08-25T11:11:30.900206Z",
     "iopub.status.idle": "2021-08-25T11:11:30.903335Z",
     "shell.execute_reply": "2021-08-25T11:11:30.902907Z"
    },
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "            # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:30.908973Z",
     "iopub.status.busy": "2021-08-25T11:11:30.908391Z",
     "iopub.status.idle": "2021-08-25T11:11:31.102106Z",
     "shell.execute_reply": "2021-08-25T11:11:31.101679Z"
    },
    "id": "a1jXoAMRZyvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 16]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=1562, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=True,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.110197Z",
     "iopub.status.busy": "2021-08-25T11:11:31.109573Z",
     "iopub.status.idle": "2021-08-25T11:11:31.112051Z",
     "shell.execute_reply": "2021-08-25T11:11:31.111606Z"
    },
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        self.d_model = d_model\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inp,tar = inputs[0], inputs[1]\n",
    " \n",
    "        enc_output = self.encoder(inp, training=False )  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask=None, padding_mask=None)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.117919Z",
     "iopub.status.busy": "2021-08-25T11:11:31.117300Z",
     "iopub.status.idle": "2021-08-25T11:11:31.560028Z",
     "shell.execute_reply": "2021-08-25T11:11:31.559558Z"
    },
    "id": "tJ4fbQcIkHW1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begining\n",
      "tf.Tensor(\n",
      "[[5476  354 1500 3358 4424 5551  861 4211 2342 5354 4829 7978 3677 3927\n",
      "  2566 4919    7 4659 4471 2736 2855 3405 3606 4091  829 4888 5214 5970\n",
      "  5823 3234 5243 2886  881 4672 7548 5645]\n",
      " [3018 5471 7279 1174 7221 5540 2368 7232 4441 5960 2981 1634 3515 7720\n",
      "   569 7164 1987 2585 6969 2218 6950  153 5713 4135 4456 7923 4918 7454\n",
      "  5888 5223  124 3848 6347 1529 7776 6037]], shape=(2, 36), dtype=int64)\n",
      "['test', 'test2']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/nikkokks/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/nikkokks/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/nikkokks/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/input_spec.py:202 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_1 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-97058b0cdc97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtemp_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfn_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# (batch_size, tar_seq_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-236-25e8b28d3bee>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begining'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, inp_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-195-c4c1faa9cd5a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3382\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/nikkokks/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/nikkokks/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/nikkokks/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/nikkokks/.local/lib/python3.6/site-packages/keras/engine/input_spec.py:202 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_1 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>]\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "     target_vocab_size=8000,\n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = ['test','test2']\n",
    "temp_target = tf.random.uniform((2, 36), dtype=tf.int64, minval=0, maxval=8000)\n",
    "\n",
    "fn_out, _ = sample_transformer([temp_input, temp_target], training=True)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for `num_layers, d_model, dff` have been reduced. \n",
    "\n",
    "The base model described in the [paper](https://arxiv.org/abs/1706.03762) used: `num_layers=6, d_model=512, dff=2048`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.564217Z",
     "iopub.status.busy": "2021-08-25T11:11:31.563682Z",
     "iopub.status.idle": "2021-08-25T11:11:31.565481Z",
     "shell.execute_reply": "2021-08-25T11:11:31.565815Z"
    },
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * \\min(step{\\_}num^{-0.5}, step{\\_}num \\cdot warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.570971Z",
     "iopub.status.busy": "2021-08-25T11:11:31.570438Z",
     "iopub.status.idle": "2021-08-25T11:11:31.572287Z",
     "shell.execute_reply": "2021-08-25T11:11:31.572643Z"
    },
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.576505Z",
     "iopub.status.busy": "2021-08-25T11:11:31.575987Z",
     "iopub.status.idle": "2021-08-25T11:11:31.578712Z",
     "shell.execute_reply": "2021-08-25T11:11:31.578270Z"
    },
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.582872Z",
     "iopub.status.busy": "2021-08-25T11:11:31.582294Z",
     "iopub.status.idle": "2021-08-25T11:11:31.715560Z",
     "shell.execute_reply": "2021-08-25T11:11:31.715129Z"
    },
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.719517Z",
     "iopub.status.busy": "2021-08-25T11:11:31.718956Z",
     "iopub.status.idle": "2021-08-25T11:11:31.721390Z",
     "shell.execute_reply": "2021-08-25T11:11:31.720917Z"
    },
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.727222Z",
     "iopub.status.busy": "2021-08-25T11:11:31.726646Z",
     "iopub.status.idle": "2021-08-25T11:11:31.728848Z",
     "shell.execute_reply": "2021-08-25T11:11:31.728446Z"
    },
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.734983Z",
     "iopub.status.busy": "2021-08-25T11:11:31.734362Z",
     "iopub.status.idle": "2021-08-25T11:11:31.740258Z",
     "shell.execute_reply": "2021-08-25T11:11:31.739859Z"
    },
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.745734Z",
     "iopub.status.busy": "2021-08-25T11:11:31.745204Z",
     "iopub.status.idle": "2021-08-25T11:11:31.840746Z",
     "shell.execute_reply": "2021-08-25T11:11:31.840234Z"
    },
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    target_vocab_size=tokenizer.get_vocab_size(),\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.846066Z",
     "iopub.status.busy": "2021-08-25T11:11:31.845451Z",
     "iopub.status.idle": "2021-08-25T11:11:31.847115Z",
     "shell.execute_reply": "2021-08-25T11:11:31.847467Z"
    },
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](https://www.tensorflow.org/text/tutorials/text_generation)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each token, *self-attention* allows it to look at the previous tokens in the input sequence to better predict the next token.\n",
    "\n",
    "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.851027Z",
     "iopub.status.busy": "2021-08-25T11:11:31.850475Z",
     "iopub.status.idle": "2021-08-25T11:11:31.852167Z",
     "shell.execute_reply": "2021-08-25T11:11:31.852503Z"
    },
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.858607Z",
     "iopub.status.busy": "2021-08-25T11:11:31.858001Z",
     "iopub.status.idle": "2021-08-25T11:11:31.859617Z",
     "shell.execute_reply": "2021-08-25T11:11:31.859941Z"
    },
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = []\n",
    "    tar_real = []\n",
    "\n",
    "    for i in tar:\n",
    "        tar_inp.append(i[:-1])\n",
    "        tar_real.append(i[1:])\n",
    "    tar_inp = np.array(tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer([inp, tar_inp],\n",
    "                                 training = True)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_examples = pd.read_csv('../data/df_train.csv')\n",
    "#val_examples = pd.read_csv('../data/df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "train_examples = tf.data.Dataset.from_tensor_slices({'seq':train_examples['seq'].values,'name':train_examples['name'].values})\n",
    "#val_examples = tf.data.Dataset.from_tensor_slices(val_examples[['seq','name']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'MTNLRKVEAPKVAKAVAALTKKVQSVRRPTKRYGRLYATAVFTGYKRGLRNQHENTALLKVGGASTKEDSWFYVGKKCVAIYSAKNKTCVPGKPKSVKSHKRAIWGKITRPHGTSGALRAKFVRNLPGNFIGKRIRIMLYPSRI'],\n",
      "      dtype=object)>, 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'60S ribosomal protein L35a'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_batches(ds):\n",
    "    return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(1)\n",
    "      #.map(lambda x: preparation_data(x), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "#val_batches = make_batches(val_examples)\n",
    "for i in train_batches:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_batches:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikkokks/anaconda3/envs/TLA/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 2]), list([0, 3])], dtype=object)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:11:31.865318Z",
     "iopub.status.busy": "2021-08-25T11:11:31.864564Z",
     "iopub.status.idle": "2021-08-25T11:26:47.809623Z",
     "shell.execute_reply": "2021-08-25T11:26:47.809152Z"
    },
    "id": "bbvmaKNiznHZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.2603 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 9.1014 Accuracy 0.0142\n",
      "Epoch 1 Batch 100 Loss 8.9751 Accuracy 0.0566\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, infos) in enumerate(train_batches):\n",
    "        inp,tar = infos['seq'],infos['name']\n",
    "        inp = [str(i.decode('ascii')) for i in inp.numpy()]\n",
    "        inp = input_encoder.encode_X(inp,90000)\n",
    "        tar = [str(i.decode('ascii')) for i in tar.numpy()]\n",
    "        tar =[ tokenizer.encode(i).ids for i in tar]\n",
    "        \n",
    "        inp[0] = inp[0][:,:512]\n",
    "\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "    break\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "\n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:26:47.820518Z",
     "iopub.status.busy": "2021-08-25T11:26:47.819906Z",
     "iopub.status.idle": "2021-08-25T11:26:47.821685Z",
     "shell.execute_reply": "2021-08-25T11:26:47.822054Z"
    },
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, tokenizers, transformer):\n",
    "        self.tokenizers = tokenizers\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __call__(self, sentence, max_length=20):\n",
    "        # input sentence is portuguese, hence adding the start and end token\n",
    "        assert isinstance(sentence, tf.Tensor)\n",
    "        if len(sentence.shape) == 0:\n",
    "              sentence = sentence[tf.newaxis]\n",
    "\n",
    "        sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "    \n",
    "        encoder_input = sentence\n",
    "\n",
    "        # as the target is english, the first token to the transformer should be the\n",
    "        # english start token.\n",
    "        start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "        start = start_end[0][tf.newaxis]\n",
    "        end = start_end[1][tf.newaxis]\n",
    "\n",
    "        # `tf.TensorArray` is required here (instead of a python list) so that the\n",
    "        # dynamic-loop can be traced by `tf.function`.\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        output_array = output_array.write(0, start)\n",
    "    \n",
    "        for i in tf.range(max_length):\n",
    "            output = tf.transpose(output_array.stack())\n",
    "            predictions, _ = self.transformer([encoder_input, output], training=False)\n",
    "     \n",
    "            # select the last token from the seq_len dimension\n",
    "            predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "            # concatentate the predicted_id to the output which is given to the decoder\n",
    "            # as its input.\n",
    "            output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "            if predicted_id == end:\n",
    "                break\n",
    "\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        # output.shape (1, tokens)\n",
    "        text = tokenizers.en.detokenize(output)[0]  # shape: ()\n",
    "\n",
    "        tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "        # `tf.function` prevents us from using the attention_weights that were\n",
    "        # calculated on the last iteration of the loop. So recalculate them outside\n",
    "        # the loop.\n",
    "        _, attention_weights = self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "\n",
    "        return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:26:47.826897Z",
     "iopub.status.busy": "2021-08-25T11:26:47.826210Z",
     "iopub.status.idle": "2021-08-25T11:26:47.828701Z",
     "shell.execute_reply": "2021-08-25T11:26:47.828137Z"
    },
    "id": "4OR2D4EXeIRY"
   },
   "outputs": [],
   "source": [
    "translator = Translator(tokenizers, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:26:47.833332Z",
     "iopub.status.busy": "2021-08-25T11:26:47.832707Z",
     "iopub.status.idle": "2021-08-25T11:26:47.835221Z",
     "shell.execute_reply": "2021-08-25T11:26:47.834678Z"
    },
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, ground_truth):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "    print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:26:47.839906Z",
     "iopub.status.busy": "2021-08-25T11:26:47.839282Z",
     "iopub.status.idle": "2021-08-25T11:26:49.747370Z",
     "shell.execute_reply": "2021-08-25T11:26:49.746888Z"
    },
    "id": "YsxrAlvFG8SZ"
   },
   "outputs": [],
   "source": [
    "sentence = \"este  um problema que temos que resolver.\"\n",
    "ground_truth = \"this is a problem we have to solve .\"\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(sentence))\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:26:49.752680Z",
     "iopub.status.busy": "2021-08-25T11:26:49.751869Z",
     "iopub.status.idle": "2021-08-25T11:26:50.796373Z",
     "shell.execute_reply": "2021-08-25T11:26:50.795848Z"
    },
    "id": "7EH5y_aqI4t1"
   },
   "outputs": [],
   "source": [
    "sentence = \"os meus vizinhos ouviram sobre esta ideia.\"\n",
    "ground_truth = \"and my neighboring homes heard about this idea .\"\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(sentence))\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:26:50.802248Z",
     "iopub.status.busy": "2021-08-25T11:26:50.801254Z",
     "iopub.status.idle": "2021-08-25T11:26:52.887129Z",
     "shell.execute_reply": "2021-08-25T11:26:52.887510Z"
    },
    "id": "J-hVCTSUMlkb"
   },
   "outputs": [],
   "source": [
    "sentence = \"vou ento muito rapidamente partilhar convosco algumas histrias de algumas coisas mgicas que aconteceram.\"\n",
    "ground_truth = \"so i \\'ll just share with you some stories very quickly of some magical things that have happened .\"\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(sentence))\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOyiOetL2l60"
   },
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTK3g2UL2oMc"
   },
   "source": [
    "That inference model is working, so next you'll export it as a `tf.saved_model`.\n",
    "\n",
    "To do that, wrap it in yet another `tf.Module` sub-class, this time with a `tf.function` on the `__call__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:27:00.064287Z",
     "iopub.status.busy": "2021-08-25T11:27:00.063376Z",
     "iopub.status.idle": "2021-08-25T11:27:00.065533Z",
     "shell.execute_reply": "2021-08-25T11:27:00.065954Z"
    },
    "id": "GRmzkibLusQi"
   },
   "outputs": [],
   "source": [
    "class ExportTranslator(tf.Module):\n",
    "    def __init__(self, translator):\n",
    "        self.translator = translator\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "    def __call__(self, sentence):\n",
    "        (result, \n",
    "     tokens,\n",
    "     attention_weights) = self.translator(sentence, max_length=100)\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9f_pmEA4kql"
   },
   "source": [
    "In the above `tf.function` only the output sentence is returned. Thanks to the [non-strict execution](https://tensorflow.org/guide/intro_to_graphs) in `tf.function` any unnecessary values are never computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:27:00.070719Z",
     "iopub.status.busy": "2021-08-25T11:27:00.069827Z",
     "iopub.status.idle": "2021-08-25T11:27:00.072089Z",
     "shell.execute_reply": "2021-08-25T11:27:00.072451Z"
    },
    "id": "EfomoJDP2n5n"
   },
   "outputs": [],
   "source": [
    "translator = ExportTranslator(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUfoCWPS9LuB"
   },
   "source": [
    "Since the model is decoding the predictions using `tf.argmax` the predictions are deterministic. The original model and one reloaded from its `SavedModel` should give identical predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:27:00.077530Z",
     "iopub.status.busy": "2021-08-25T11:27:00.076624Z",
     "iopub.status.idle": "2021-08-25T11:27:05.721117Z",
     "shell.execute_reply": "2021-08-25T11:27:05.721553Z"
    },
    "id": "hAlqyycz3IYL"
   },
   "outputs": [],
   "source": [
    "translator(\"este  o primeiro livro que eu fiz.\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:27:05.792063Z",
     "iopub.status.busy": "2021-08-25T11:27:05.755806Z",
     "iopub.status.idle": "2021-08-25T11:27:30.775322Z",
     "shell.execute_reply": "2021-08-25T11:27:30.781286Z"
    },
    "id": "ar3LO-Vuvlnv"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(translator, export_dir='translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:27:30.789538Z",
     "iopub.status.busy": "2021-08-25T11:27:30.788802Z",
     "iopub.status.idle": "2021-08-25T11:27:40.495624Z",
     "shell.execute_reply": "2021-08-25T11:27:40.495075Z"
    },
    "id": "8WUflwyT1SEF"
   },
   "outputs": [],
   "source": [
    "reloaded = tf.saved_model.load('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T11:27:40.503141Z",
     "iopub.status.busy": "2021-08-25T11:27:40.500358Z",
     "iopub.status.idle": "2021-08-25T11:27:43.205255Z",
     "shell.execute_reply": "2021-08-25T11:27:43.204752Z"
    },
    "id": "-sBTBWwR1XMr"
   },
   "outputs": [],
   "source": [
    "reloaded(\"este  o primeiro livro que eu fiz.\").numpy()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "transformer.ipynb",
   "provenance": [
    {
     "file_id": "1fpiHY_g7b1-bs_sSRWcbiw9qv4eDU4QZ",
     "timestamp": 1628275335747
    },
    {
     "file_id": "https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb",
     "timestamp": 1628273726995
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
